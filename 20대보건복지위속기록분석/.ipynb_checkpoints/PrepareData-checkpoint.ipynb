{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 보건복지위원회 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading Mylib...\n",
      "==============\n",
      "Mylib imported!\n",
      "==============\n"
     ]
    }
   ],
   "source": [
    "import random, unicodedata\n",
    "from Mylib import *\n",
    "\n",
    "# =============================================================================\n",
    "# Read Data\n",
    "# =============================================================================\n",
    "HWC = pd.read_csv('./data/meetinglog20thHWC(N).csv', encoding='utf=8')\n",
    "HWC = HWC.drop('KEYWORD', 1) # 불필요한 열 제거\n",
    "HWC.AGENDA.apply(lambda x: x[:20])\n",
    "\n",
    "# 정당별 요약치 (무소속 제외)\n",
    "S1 = HWC[pd.notna(HWC['PARTY'])].groupby(['MEETING_NAME']).size()\n",
    "S2 = HWC[pd.notna(HWC['PARTY'])].groupby(['PARTY','SPEAKER']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1차 불용어 필터링\n",
    "* 구두점을 기준으로 어절을 추출한 뒤 최빈 순으로 불용어를 정함 $\\rightarrow$ 712여개 추출."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20301/20301 [00:08<00:00, 2336.08it/s]\n"
     ]
    }
   ],
   "source": [
    "cnt = Counter([tkn for s in HWC.CONTENT for tkn in re.split('[ .!?]', s)])\n",
    "frqtab = sorted(cnt.items(), key = lambda x: x[1], reverse = True)[:732]\n",
    "include = ['예산', '지원', '건강', '보험', '법', '맞춤', '출산', '수도', '의약품', '약사', '의료',\n",
    "          '어린이', '문재인', '사회', '연금', '장애', '사업', '재정', '인력', '위원회', '보육', '정책',\n",
    "          '보장', '조사', '제도', '환자', '조치', '편성', '개정', '부담', '보건의료', '식약처', '심사',\n",
    "          '노인', '병원', '신생', '계획', '운영', '감염', '식품', '기준', '심의', '안전', '예방',\n",
    "          '일자리', '사업', '규정', '부과', '체계', '메르스', '글로벌', '책임', '서비스', '업무', '현행',\n",
    "          '계란', '소득', '평가']\n",
    "frqtab = [k for k, f in frqtab if not re.search('|'.join(include), k)]\n",
    "HWC.CONTENT = [' '.join([si for si in re.split('[ ]', s) if si not in frqtab]) \n",
    "               for s in tqdm(HWC.CONTENT)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2차 불용어 필터링\n",
    "* 용어 수작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get NNP + NNGs for LDA and Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20301/20301 [01:39<00:00, 203.96it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data_for_noun = HWC.copy()\n",
    "    data_for_noun.loc[data_for_noun.SPEAKER == '박인숙 위원', 'PARTY'] = '자유한국당'\n",
    "    data_for_noun.loc[pd.isna(data_for_noun.PARTY), 'PARTY'] = '非의원'\n",
    "    \n",
    "    data_for_noun = data_for_noun.assign(token = [get_noun(doc)\n",
    "                                                  for doc in tqdm(data_for_noun.CONTENT.values)])\n",
    "    data_for_noun = data_for_noun.loc[[i for i, tkn in data_for_noun.token.items() \n",
    "                                       if len(tkn) > 0]]\n",
    "    data_for_noun.to_pickle(\"./result/HWC_noun_token0422.pkl\") # for LDA\n",
    "    \n",
    "    data_for_noun = data_for_noun.drop('token', 1)\n",
    "    data_for_noun = data_for_noun.assign(token = [[get_noun(doc) for doc in re.split('[?.!]', corp)] \n",
    "                                                  for corp in tqdm(data_for_noun.CONTENT.values)])\n",
    "    data_for_noun.to_pickle('./result/HWC_noun_token_m.pkl') # for Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정당공약 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "더불어민주당.txt: 100%|██████████| 562/562 [00:06<00:00, 87.58it/s] \n",
      "미래통합당.txt: 100%|██████████| 579/579 [00:04<00:00, 131.11it/s]\n",
      "민생당.txt: 100%|██████████| 392/392 [00:02<00:00, 170.37it/s]\n",
      "친박신당.txt: 100%|██████████| 355/355 [00:02<00:00, 146.35it/s]\n",
      "국민의당.txt: 100%|██████████| 422/422 [00:02<00:00, 197.46it/s]\n",
      "우리공화당.txt: 100%|██████████| 449/449 [00:02<00:00, 181.66it/s]\n",
      "민중당.txt: 100%|██████████| 406/406 [00:01<00:00, 209.12it/s]\n",
      "정의당.txt: 100%|██████████| 572/572 [00:02<00:00, 208.23it/s]\n",
      "한국경제당.txt: 100%|██████████| 297/297 [00:01<00:00, 207.71it/s]\n"
     ]
    }
   ],
   "source": [
    "fnames = [i for i in os.listdir('./pdfminer/21e_texts') if re.search('DS_Store', i) is None and re.search('.txt', i)]\n",
    "paths = ['./pdfminer/21e_texts/' + i for i in fnames]\n",
    "election_21st = {}\n",
    "for i, f in enumerate(fnames):\n",
    "    doc = pd.read_table(paths[i], header = None)[0]\n",
    "    tmp = []\n",
    "    for d in tqdm(doc, f):\n",
    "        tmp.append(get_noun(d, rms = ['선거명', '정당명','국회의원 선거', '국회의원선거', '정책순위',\n",
    "                                      '제목', '이행방법', '목 표', '목표', '이행기간', '정책분야',\n",
    "                                      '재원조달방법', '재원조달',\n",
    "                                      unicodedata.normalize('NFC', f[:-4])]))\n",
    "    election_21st['{}'.format(f[:-4])] = tmp\n",
    "with open('./data/election_21st.pickle', 'wb') as f:\n",
    "    pickle.dump(election_21st, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문재인 19대 대선 공약 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 601/601 [00:06<00:00, 92.17it/s] \n"
     ]
    }
   ],
   "source": [
    "MJI19thPE = []\n",
    "doc = pd.read_table('./pdfminer/19pe_text/MJI19thPE.txt', header = None)[0]\n",
    "tmp = []\n",
    "for d in tqdm(doc):\n",
    "    tmp.append(get_noun(d, rms = ['선거명', '후보자명', '공약순위', '제목', '제19대 대통령선거', '기호', '문재인',\n",
    "                                 '소속정당명', '더불어민주당', '목표', '이행기간', '재원조달방안 등']))\n",
    "    \n",
    "with open('./data/MJI19thPE.pickle', 'wb') as f:\n",
    "    pickle.dump(tmp, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 샘플 문서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "이재명_intv.txt: 100%|██████████| 76/76 [00:00<00:00, 165.98it/s]\n",
      "신재민_intv.txt: 100%|██████████| 15/15 [00:00<00:00, 117.26it/s]\n"
     ]
    }
   ],
   "source": [
    "wd ='./data/'\n",
    "fnames = [i for i in listdir(wd) if re.search('intv', i)]\n",
    "paths = [wd + i for i in fnames]\n",
    "\n",
    "result_dict = {}\n",
    "for i, f in enumerate(fnames):\n",
    "    doc = pd.read_table(paths[i], header = None)[0]\n",
    "    tmp = []\n",
    "    for d in tqdm(doc, f):\n",
    "        tmp += get_noun(d)\n",
    "    result_dict['{}'.format(f[:-4])] = tmp\n",
    "\n",
    "with open('./data/sample_doc.pickle', 'wb') as f:\n",
    "    pickle.dump(result_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
