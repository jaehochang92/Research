{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 보건복지위원회 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, unicodedata\n",
    "from Mylib import *\n",
    "\n",
    "# =============================================================================\n",
    "# Read Data\n",
    "# =============================================================================\n",
    "HWC = pd.read_csv('./data/meetinglog20thHWC(N).csv', encoding='utf=8')\n",
    "HWC = HWC.drop('KEYWORD', 1) # 불필요한 열 제거\n",
    "HWC.AGENDA.apply(lambda x: x[:20])\n",
    "\n",
    "# 정당별 요약치 (무소속 제외)\n",
    "S1 = HWC[pd.notna(HWC['PARTY'])].groupby(['MEETING_NAME']).size()\n",
    "S2 = HWC[pd.notna(HWC['PARTY'])].groupby(['PARTY','SPEAKER']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1차 불용어 필터링\n",
    "* 구두점을 기준으로 어절을 추출한 뒤 최빈 순으로 불용어를 정함 $\\rightarrow$ 712여개 추출."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 20301/20301 [00:05<00:00, 4015.31it/s]\n"
     ]
    }
   ],
   "source": [
    "cnt = Counter([tkn for s in HWC.CONTENT for tkn in re.split('[ .!?]', s)])\n",
    "frqtab = sorted(cnt.items(), key = lambda x: x[1], reverse = True)[:732]\n",
    "include = ['예산', '지원', '건강', '보험', '법', '맞춤', '출산', '수도', '의약품', '약사', '의료',\n",
    "          '어린이', '문재인', '사회', '연금', '장애', '사업', '재정', '인력', '위원회', '보육', '정책',\n",
    "          '보장', '조사', '제도', '환자', '조치', '편성', '개정', '부담', '보건의료', '식약처', '심사',\n",
    "          '노인', '병원', '신생', '계획', '운영', '감염', '식품', '기준', '심의', '안전', '예방',\n",
    "          '일자리', '사업', '규정', '부과', '체계', '메르스', '글로벌', '책임', '서비스', '업무', '현행',\n",
    "          '계란', '소득', '평가']\n",
    "frqtab = [k for k, f in frqtab if not re.search('|'.join(include), k)]\n",
    "HWC.CONTENT = [' '.join([si for si in re.split('[ ]', s) if si not in frqtab]) \n",
    "               for s in tqdm(HWC.CONTENT)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2차 불용어 필터링\n",
    "* 용어 수작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = ['']\n",
    "man = pd.read_csv('./data/190915_용어_수작업.csv') # Manual term removals\n",
    "man = man[man['code'] == 1]['단어']\n",
    "rms.extend(man)\n",
    "HWC.CONTENT = [' '.join([si for si in re.split('[ ]', s) if si not in rms]) \n",
    "               for s in tqdm(HWC.CONTENT)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get NNP + NNGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/20301 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Install MeCab in order to use it: http://konlpy.org/en/latest/install/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_mecab.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dicpath)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-d %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdicpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s/data/tagset/mecab.json'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstallpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Tagger' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-3e31b1cf3f4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     data_for_noun = data_for_noun.assign(token = [[get_noun(doc) for doc in docs] \n\u001b[1;32m----> 7\u001b[1;33m                                                   for docs in tqdm(data_for_noun.CONTENT.values)])\n\u001b[0m\u001b[0;32m      8\u001b[0m     data_for_noun = data_for_noun.loc[[i for i, tkn in data_for_noun.token.items() \n\u001b[0;32m      9\u001b[0m                                        if len(tkn) > 0]]\n",
      "\u001b[1;32m<ipython-input-23-3e31b1cf3f4d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     data_for_noun = data_for_noun.assign(token = [[get_noun(doc) for doc in docs] \n\u001b[1;32m----> 7\u001b[1;33m                                                   for docs in tqdm(data_for_noun.CONTENT.values)])\n\u001b[0m\u001b[0;32m      8\u001b[0m     data_for_noun = data_for_noun.loc[[i for i, tkn in data_for_noun.token.items() \n\u001b[0;32m      9\u001b[0m                                        if len(tkn) > 0]]\n",
      "\u001b[1;32m<ipython-input-23-3e31b1cf3f4d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdata_for_noun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_for_noun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPARTY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PARTY'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'非의원'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     data_for_noun = data_for_noun.assign(token = [[get_noun(doc) for doc in docs] \n\u001b[0m\u001b[0;32m      7\u001b[0m                                                   for docs in tqdm(data_for_noun.CONTENT.values)])\n\u001b[0;32m      8\u001b[0m     data_for_noun = data_for_noun.loc[[i for i, tkn in data_for_noun.token.items() \n",
      "\u001b[1;32m~\\GoogleDrive\\Research\\HCLee\\Mylib.py\u001b[0m in \u001b[0;36mget_noun\u001b[1;34m(string, rms)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[0mstring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[0mmecab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMecab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m     \u001b[0mnouns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_mecab.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dicpath)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The MeCab dictionary does not exist at \"%s\". Is the dictionary correctly installed?\\nYou can also try entering the dictionary path when initializing the Mecab class: \"Mecab(\\'/some/dic/path\\')\"'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdicpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Install MeCab in order to use it: http://konlpy.org/en/latest/install/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Install MeCab in order to use it: http://konlpy.org/en/latest/install/"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data_for_noun = HWC.copy()\n",
    "    data_for_noun.loc[data_for_noun.SPEAKER == '박인숙 위원', 'PARTY'] = '자유한국당'\n",
    "    data_for_noun.loc[pd.isna(data_for_noun.PARTY), 'PARTY'] = '非의원'\n",
    "    \n",
    "    data_for_noun = data_for_noun.assign(token = [[get_noun(doc) for doc in docs] \n",
    "                                                  for docs in tqdm(data_for_noun.CONTENT.values)])\n",
    "    data_for_noun = data_for_noun.loc[[i for i, tkn in data_for_noun.token.items() \n",
    "                                       if len(tkn) > 0]]\n",
    "    data_for_noun.to_pickle(\"./result/HWC_noun_token0422.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정당공약 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "더불어민주당.txt: 100%|██████████| 562/562 [00:06<00:00, 87.58it/s] \n",
      "미래통합당.txt: 100%|██████████| 579/579 [00:04<00:00, 131.11it/s]\n",
      "민생당.txt: 100%|██████████| 392/392 [00:02<00:00, 170.37it/s]\n",
      "친박신당.txt: 100%|██████████| 355/355 [00:02<00:00, 146.35it/s]\n",
      "국민의당.txt: 100%|██████████| 422/422 [00:02<00:00, 197.46it/s]\n",
      "우리공화당.txt: 100%|██████████| 449/449 [00:02<00:00, 181.66it/s]\n",
      "민중당.txt: 100%|██████████| 406/406 [00:01<00:00, 209.12it/s]\n",
      "정의당.txt: 100%|██████████| 572/572 [00:02<00:00, 208.23it/s]\n",
      "한국경제당.txt: 100%|██████████| 297/297 [00:01<00:00, 207.71it/s]\n"
     ]
    }
   ],
   "source": [
    "fnames = [i for i in os.listdir('./pdfminer/21e_texts') if re.search('DS_Store', i) is None and re.search('.txt', i)]\n",
    "paths = ['./pdfminer/21e_texts/' + i for i in fnames]\n",
    "election_21st = {}\n",
    "for i, f in enumerate(fnames):\n",
    "    doc = pd.read_table(paths[i], header = None)[0]\n",
    "    tmp = []\n",
    "    for d in tqdm(doc, f):\n",
    "        tmp.append(get_noun(d, rms = ['선거명', '정당명','국회의원 선거', '국회의원선거', '정책순위',\n",
    "                                      '제목', '이행방법', '목 표', '목표', '이행기간', '정책분야',\n",
    "                                      '재원조달방법', '재원조달',\n",
    "                                      unicodedata.normalize('NFC', f[:-4])]))\n",
    "    election_21st['{}'.format(f[:-4])] = tmp\n",
    "with open('./data/election_21st.pickle', 'wb') as f:\n",
    "    pickle.dump(election_21st, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문재인 19대 대선 공약 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 601/601 [00:06<00:00, 92.17it/s] \n"
     ]
    }
   ],
   "source": [
    "MJI19thPE = []\n",
    "doc = pd.read_table('./pdfminer/19pe_text/MJI19thPE.txt', header = None)[0]\n",
    "tmp = []\n",
    "for d in tqdm(doc):\n",
    "    tmp.append(get_noun(d, rms = ['선거명', '후보자명', '공약순위', '제목', '제19대 대통령선거', '기호', '문재인',\n",
    "                                 '소속정당명', '더불어민주당', '목표', '이행기간', '재원조달방안 등']))\n",
    "    \n",
    "with open('./data/MJI19thPE.pickle', 'wb') as f:\n",
    "    pickle.dump(tmp, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 샘플 문서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "이재명_intv.txt: 100%|██████████| 76/76 [00:00<00:00, 165.98it/s]\n",
      "신재민_intv.txt: 100%|██████████| 15/15 [00:00<00:00, 117.26it/s]\n"
     ]
    }
   ],
   "source": [
    "wd ='./data/'\n",
    "fnames = [i for i in listdir(wd) if re.search('intv', i)]\n",
    "paths = [wd + i for i in fnames]\n",
    "\n",
    "result_dict = {}\n",
    "for i, f in enumerate(fnames):\n",
    "    doc = pd.read_table(paths[i], header = None)[0]\n",
    "    tmp = []\n",
    "    for d in tqdm(doc, f):\n",
    "        tmp += get_noun(d)\n",
    "    result_dict['{}'.format(f[:-4])] = tmp\n",
    "\n",
    "with open('./data/sample_doc.pickle', 'wb') as f:\n",
    "    pickle.dump(result_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
