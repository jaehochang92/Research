{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading Mylib...\n",
      "==============\n",
      "Mylib imported!\n",
      "==============\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import random\n",
    "import pprint \n",
    "from Mylib import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20대 보건복지부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Preparation\n",
    "raw_data = pd.read_pickle('./result/HWC_noun_token_m.pkl')\n",
    "raw_data = raw_data.sort_values(['CONFER_NUM', 'SEQ_NO'])\n",
    "raw_data = raw_data.loc[[idx for idx in raw_data.index if raw_data.PARTY.loc[idx] != '非의원']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load final lda model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_rms = pd.read_csv('./data/190915_용어_수작업.csv') # Manual term removals\n",
    "manual_rms = manual_rms[manual_rms['code'] == 1]['단어'].values \n",
    "manual_rms = [rm for rm in manual_rms if len(rm) == 1]\n",
    "\n",
    "speakers = set([s for tkns in [spker.split(' ') for spker in raw_data.SPEAKER] for s in tkns if len(s) <= 3 and s not in ['위원장', '위원', '의원', '진술인', '참고인']])\n",
    "manual_rms = np.append(manual_rms, [\"계속\", '료', '박정', '말씀', '생각', '얘기', '질의', '발언', '국민'])\n",
    "\n",
    "raw_data.token = [[[tkn for tkn in doc if tkn not in manual_rms] for doc in corp] for corp in tqdm(raw_data.token)]\n",
    "raw_data.token = [[doc for doc in corp if doc != []] for corp in tqdm(raw_data.token)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = '200427_0005_20대_보건복지부_발언정제'\n",
    "'./result/'\n",
    "flda = gs.models.LdaMulticore.load(f'./result/{path}/ldafit.pickle')\n",
    "fid2word = gs.models.LdaMulticore.load(f'./result/{path}/ldafit.pickle.id2word')\n",
    "topiced_terms = set([flda.id2word[term] for t in range(flda.num_topics) for term,p in flda.get_topic_terms(t)])\n",
    "\n",
    "raw_data.token = [[[tkn for tkn in doc if tkn in topiced_terms] for doc in corp] for corp in tqdm(raw_data.token)]\n",
    "raw_data = raw_data.loc[[i for i, d in raw_data.token.items() if d != []]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONFER_NUM</th>\n",
       "      <th>MEETING_NAME</th>\n",
       "      <th>SEQ_NO</th>\n",
       "      <th>AGENDA</th>\n",
       "      <th>SPEAKER</th>\n",
       "      <th>PARTY</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5294</th>\n",
       "      <td>48725</td>\n",
       "      <td>제364회(2018.09.01-2018.12.09)</td>\n",
       "      <td>11</td>\n",
       "      <td>1. 2019년도 예산안(계속)가. 보건복지부 소관나. 식품의약품안전처 소관2. 2...</td>\n",
       "      <td>남인순 위원</td>\n",
       "      <td>더불어민주당</td>\n",
       "      <td>다함께돌봄사업을 지역아동센터도 오랫동안 어렵게 현장에서 왔던 그룹들이기 부분과 균형...</td>\n",
       "      <td>[[사업, 아동], [], []]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5295</th>\n",
       "      <td>48725</td>\n",
       "      <td>제364회(2018.09.01-2018.12.09)</td>\n",
       "      <td>13</td>\n",
       "      <td>1. 2019년도 예산안(계속)가. 보건복지부 소관나. 식품의약품안전처 소관2. 2...</td>\n",
       "      <td>남인순 위원</td>\n",
       "      <td>더불어민주당</td>\n",
       "      <td>지침을 내려보내 주십시오.</td>\n",
       "      <td>[[], []]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296</th>\n",
       "      <td>48725</td>\n",
       "      <td>제364회(2018.09.01-2018.12.09)</td>\n",
       "      <td>15</td>\n",
       "      <td>1. 2019년도 예산안(계속)가. 보건복지부 소관나. 식품의약품안전처 소관2. 2...</td>\n",
       "      <td>남인순 위원</td>\n",
       "      <td>더불어민주당</td>\n",
       "      <td>현장에서 혼선이 있습니다.</td>\n",
       "      <td>[[], []]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CONFER_NUM                  MEETING_NAME  SEQ_NO  \\\n",
       "5294       48725  제364회(2018.09.01-2018.12.09)      11   \n",
       "5295       48725  제364회(2018.09.01-2018.12.09)      13   \n",
       "5296       48725  제364회(2018.09.01-2018.12.09)      15   \n",
       "\n",
       "                                                 AGENDA SPEAKER   PARTY  \\\n",
       "5294  1. 2019년도 예산안(계속)가. 보건복지부 소관나. 식품의약품안전처 소관2. 2...  남인순 위원  더불어민주당   \n",
       "5295  1. 2019년도 예산안(계속)가. 보건복지부 소관나. 식품의약품안전처 소관2. 2...  남인순 위원  더불어민주당   \n",
       "5296  1. 2019년도 예산안(계속)가. 보건복지부 소관나. 식품의약품안전처 소관2. 2...  남인순 위원  더불어민주당   \n",
       "\n",
       "                                                CONTENT               token  \n",
       "5294  다함께돌봄사업을 지역아동센터도 오랫동안 어렵게 현장에서 왔던 그룹들이기 부분과 균형...  [[사업, 아동], [], []]  \n",
       "5295                                     지침을 내려보내 주십시오.            [[], []]  \n",
       "5296                                     현장에서 혼선이 있습니다.            [[], []]  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ngram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 9621/9621 [00:00<00:00, 1203357.75it/s]\n"
     ]
    }
   ],
   "source": [
    "ngram = 1\n",
    "raw_data.token = [make_ngram(doc, ngram, mincnt = 1, thrsh = 2) for doc in tqdm(raw_data.token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "보건복지부 = {}\n",
    "for i, (전후, 회차) in enumerate([('전체', [343, 364]), ('정권교체전', [343, 351]), ('정권교체후', [352, 364])]):\n",
    "    gdata = raw_data.loc[[idx\n",
    "                          for n in range(회차[0],회차[1]+1)\n",
    "                          for idx, m in zip(raw_data.MEETING_NAME.index, raw_data.MEETING_NAME) # filter by meetings\n",
    "                          if m.find(str(n)) > -1]]\n",
    "    doC =  {'{}'.format(p):my_list(gdata.loc[[idx for idx in gdata.index\n",
    "                                              if gdata.loc[idx].PARTY == p]].token).sum() # filter by parties\n",
    "            for p in np.unique(gdata.PARTY)}\n",
    "    doC.update({'정당통합':[d for _, C in doC.items() for d in C]})\n",
    "    보건복지부[전후] = doC\n",
    "\n",
    "for k1, i1 in 보건복지부.items():\n",
    "    for k2, i2 in i1.items():\n",
    "        보건복지부[k1][k2] = [d for d in i2 if d != []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21대 총선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = 1\n",
    "project = '21대_총선'\n",
    "#     1. Data Preparation\n",
    "doC = pd.read_pickle('./data/election_21st.pickle')\n",
    "\n",
    "rms = ['정책', '개혁', '추진'] # cliche\n",
    "총선 = {p:None for p in doC}\n",
    "for p in 총선:\n",
    "    총선[p] = [[w for w in d if w not in rms] for d in doC[p]]\n",
    "    총선[p] = [d for d in 총선[p] if d != []]\n",
    "    총선[p] = make_ngram(총선[p], ngram, mincnt = 1, thrsh = 2)\n",
    "총선.update({'정당통합':my_list([d for _, d in 총선.items()]).sum()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문재인 19대 대선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = 1\n",
    "project = '19대_대선_문재인'\n",
    "#     1. Data Preparation\n",
    "doc = pd.read_pickle('./data/MJI19thPE.pickle')\n",
    "\n",
    "rms = [''] # cliche\n",
    "문재인 = {'문재인':None}\n",
    "문재인['문재인'] = [[w for w in d if w not in rms] for d in doc]\n",
    "문재인['문재인'] = [d for d in 문재인['문재인'] if d != []]\n",
    "문재인['문재인'] = make_ngram(문재인['문재인'], ngram, mincnt = 1, thrsh = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 보건복지위 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"전체/국민의당: 2434 lines, [['보건', '복지', '위원장', '위원장'], ['위원장']]\",\n",
      " \"전체/더불어민주당: 10716 lines, [['보건', '복지', '위원회', '위원'], ['보건', '복지', '위원', \"\n",
      " \"'위원장']]\",\n",
      " \"전체/무소속: 1604 lines, [['복지', '문제'], ['위원']]\",\n",
      " \"전체/자유한국당: 6014 lines, [['위원회', '보건', '복지', '위원회', '위원회'], ['위원장', '간사', \"\n",
      " \"'간사']]\",\n",
      " \"전체/정당통합: 20768 lines, [['보건', '복지', '위원장', '위원장'], ['위원장']]\",\n",
      " \"정권교체전/국민의당: 1151 lines, [['보건', '복지', '위원장', '위원장'], ['위원장']]\",\n",
      " \"정권교체전/더불어민주당: 5683 lines, [['보건', '복지', '위원회', '위원'], ['보건', '복지', '위원', \"\n",
      " \"'위원장']]\",\n",
      " \"정권교체전/무소속: 815 lines, [['복지', '문제'], ['위원']]\",\n",
      " \"정권교체전/자유한국당: 1988 lines, [['위원회', '보건', '복지', '위원회', '위원회'], ['위원장', '간사', \"\n",
      " \"'간사']]\",\n",
      " \"정권교체전/정당통합: 9637 lines, [['보건', '복지', '위원장', '위원장'], ['위원장']]\",\n",
      " \"정권교체후/국민의당: 1283 lines, [['의결', '심사'], ['노인', '건강', '지원']]\",\n",
      " \"정권교체후/더불어민주당: 5033 lines, [['조사'], ['조사']]\",\n",
      " \"정권교체후/무소속: 789 lines, [['위원', '위원'], ['진행', '보건', '복지', '위원회', '사람', '위원']]\",\n",
      " \"정권교체후/자유한국당: 4026 lines, [['의결', '장관', '후보', '협의'], ['위원장', '장관', '후보']]\",\n",
      " \"정권교체후/정당통합: 11131 lines, [['의결', '심사'], ['노인', '건강', '지원']]\"]\n"
     ]
    }
   ],
   "source": [
    "pprint([f'{k1}/{k2}: {len(i2)} lines, {i2[2:4]}' for k1, i1 in 보건복지부.items() for k2, i2 in i1.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 총선 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"더불어민주당: 452 lines, [['벤처', '강국', '실현'], ['중소', '벤처']]\",\n",
      " \"미래통합당: 462 lines, [['국민', '희망', '공약', '개발', '단'], ['핵심', '공약']]\",\n",
      " \"민생당: 293 lines, [['코로나', '피해', '중소', '상공', '영업자'], ['民生', '지원', '극복', \"\n",
      " \"'수당', '지급']]\",\n",
      " \"친박신당: 306 lines, [['자유민주주의', '수호', '개헌', '반대', '정치'], ['박근혜', '대통령', \"\n",
      " \"'잘못', '탄핵', '자유민주주의', '기본', '질서', '위협']]\",\n",
      " \"국민의당: 316 lines, [['정치', '국회법', '정당법', '일', '정치', '실현'], ['정치', '권력', \"\n",
      " \"'사유', '민주', '통제', '강화']]\"]\n"
     ]
    }
   ],
   "source": [
    "pprint([f'{k}: {len(i)} lines, {i[:2]}' for k,i in 총선.items()][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 문재인 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"문재인: 495 lines, [['일자리', '대한민국', '공약', '분야'], ['노동']]\"]\n"
     ]
    }
   ],
   "source": [
    "pprint([f'{k}: {len(i)} lines, {i[:2]}' for k,i in 문재인.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-occurence TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def maxdiagindx(dataframe, m, dsc = True):\n",
    "    dranks = sorted([idx for idx in dataframe.index], key=lambda x: dataframe.loc[x][x], reverse=dsc)\n",
    "    return(dranks[m[0]:m[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = {f'보건복지{p}':C for p, C in 보건복지부.items()}\n",
    "# Data = {'총선':총선}\n",
    "# Data = {'문재인':문재인}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 13.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 22.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 19.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# TFIDF = copy.deepcopy(Data)\n",
    "coocs = copy.deepcopy(Data)\n",
    "keys = []\n",
    "for prj, datum in Data.items(): # 보복전, dict of dicts of lists\n",
    "    for party, tokens in tqdm(datum.items()): # 국민의당, list of lists\n",
    "        norm_corp = [my_list(t).sumtkns() for t in tokens]\n",
    "        cv = CountVectorizer()\n",
    "        X = cv.fit_transform(norm_corp)\n",
    "        if prj.find('보건복지') > -1:\n",
    "            start = 0\n",
    "            if party == '정당통합':\n",
    "                m = [start, start + 500]\n",
    "            else:\n",
    "                m = [start, start + 500]\n",
    "        else:\n",
    "            if party == '정당통합':\n",
    "                m = [1, 201]\n",
    "            else:\n",
    "                m = [1, 101]\n",
    "                \n",
    "        Xc = (X.T * X) # This is the matrix manipulation step\n",
    "        names = cv.get_feature_names() # This are the entity names (i.e. keywords)\n",
    "        cooc = pd.DataFrame(data = Xc.toarray(), columns = names, index = names)\n",
    "        dranks = maxdiagindx(cooc, m)\n",
    "        cooc.values[(np.arange(cooc.shape[0]), np.arange(cooc.shape[0]))] = 0\n",
    "        cooc = cooc.loc[dranks][dranks]\n",
    "#         print(dranks)\n",
    "        coocs[prj][party] = cooc\n",
    "\n",
    "#         2.3. Fit TFIDF\n",
    "#         tv = TfidfVectorizer(use_idf=True, min_df = .0, max_df= 1.)\n",
    "#         tv_matrix = tv.fit_transform(norm_corp).toarray()\n",
    "#         vocab = tv.get_feature_names()\n",
    "#         TFIDF[prj][party] = pd.DataFrame(tv_matrix, columns=vocab)\n",
    "\n",
    "#         2.4. Cosine Similarity\n",
    "\n",
    "#         X = TFIPF\n",
    "#         X = tfidf.apply(lambda x: x/norm(x,1), axis=0)\n",
    "#         CS = X.T.dot(X)\n",
    "#         np.fill_diagonal(CS.values, 0) # Set diag. zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Csvs saved!\n"
     ]
    }
   ],
   "source": [
    "[c.to_csv('./Gephi/csvs/' + prj + party + '.csv', encoding = 'euc-kr')\n",
    " for prj, datum in coocs.items()\n",
    " for party, c in datum.items()]\n",
    "print('Csvs saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 보건복지부 Dynamic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "from matplotlib import rc\n",
    "\n",
    "font_name = fm.FontProperties(fname=\"/Users/jangjaeho/Library/fonts/BMDOHYEON_ttf.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "# sorted([f.name for f in fm.fontManager.ttflist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, k in enumerate(keys[:1]):\n",
    "#     print(k)\n",
    "    \n",
    "#     plt.figure(figsize=(30, 30))\n",
    "#     Gdata = coocs[keys[i][0]][keys[i][1]]\n",
    "# #     print(Gdata.iloc[:5,:5])\n",
    "#     G = nx.Graph(Gdata)\n",
    "#     options = {\n",
    "#         'node_color': 'green',\n",
    "#         'node_size': 5000,\n",
    "#         'width': .1,\n",
    "#         'alpha': 0.4\n",
    "#     }\n",
    "#     # G.nodes.data()\n",
    "    \n",
    "# #     Generating gefx\n",
    "#     # linefeed = chr(10)\n",
    "#     # s = linefeed.join(nx.generate_gexf(G))\n",
    "    \n",
    "# #     1. Ordinary spring layout\n",
    "    \n",
    "#     layouts = [nx.spring_layout, nx.bipartite_layout, nx.kamada_kawai_layout,\n",
    "#                nx.shell_layout, nx.spectral_layout, nx.spiral_layout]\n",
    "#     pos = layouts[0](G)\n",
    "# #     pos = graphviz_layout(G, 'twopi')\n",
    "#     nx.draw(G, pos, **options)\n",
    "# #     nx.draw_networkx()\n",
    "# #     nx.draw_spectral(G, **options)\n",
    "# #     nx.draw_networkx_labels(G, pos, font_family = 'AppleGothic', font_size=30) # For MAC\n",
    "#     nx.draw_networkx_labels(G, pos, font_family = 'HCR Batang', font_size=25)\n",
    "    \n",
    "# #     2. Hierarchical Cluster of graph G\n",
    "\n",
    "# #     # Extract largest connected component into graph H\n",
    "# #     H = G.subgraph(next(nx.connected_components(G)))\n",
    "# #     # Makes life easier to have consecutively labeled integer nodes\n",
    "# #     H = nx.convert_node_labels_to_integers(H)\n",
    "# #     # Create parititions with hierarchical clustering\n",
    "# #     partitions = create_hc(H)\n",
    "# #     # Build blockmodel graph\n",
    "# #     BM = nx.quotient_graph(H, partitions, relabel=True)\n",
    "\n",
    "# #     # Draw original graph\n",
    "# #     pos = nx.spring_layout(H, iterations=100)\n",
    "# #     plt.subplot(211)\n",
    "# #     nx.draw(H, pos, **options)\n",
    "# #     nx.draw_networkx_labels(H, pos, font_family='HCR Batang', font_size=30)\n",
    "\n",
    "# #     # Draw block model with weighted edges and nodes sized by number of internal nodes\n",
    "# #     node_size = [BM.nodes[x]['nnodes'] * 10 for x in BM.nodes()]\n",
    "# #     edge_width = [(2 * d['weight']) for (u, v, d) in BM.edges(data=True)]\n",
    "# #     # Set positions to mean of positions of internal nodes from original graph\n",
    "# #     posBM = {}\n",
    "# #     for n in BM:\n",
    "# #         xy = np.array([pos[u] for u in BM.nodes[n]['graph']])\n",
    "# #         posBM[n] = xy.mean(axis=0)\n",
    "# #     plt.subplot(212)\n",
    "# #     nx.draw(BM, posBM, **options)\n",
    "# #     nx.draw_networkx_labels(BM, posBM, font_family='HCR Batang', font_size=30)\n",
    "    \n",
    "# #     A. Statistics\n",
    "# #     print(\"Betweenness\")\n",
    "# #     b = nx.betweenness_centrality(G)\n",
    "# #     for v in G.nodes():\n",
    "# #         print((v, b[v]))\n",
    "\n",
    "# #     print(\"Degree centrality\")\n",
    "# #     d = nx.degree_centrality(G)\n",
    "# #     for v in G.nodes():\n",
    "# #         print(\"%0.2d %5.3f\" % (v, d[v]))\n",
    "\n",
    "# #     print(\"Closeness centrality\")\n",
    "# #     c = nx.closeness_centrality(G)\n",
    "# #     for v in G.nodes():\n",
    "# #         print(\"%0.2d %5.3f\" % (v, c[v]))\n",
    "\n",
    "#     plt.axis('equal')\n",
    "#     plt.savefig('./Gephi/figures/' + k[0] + k[1] + '.png', )\n",
    "# #     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
