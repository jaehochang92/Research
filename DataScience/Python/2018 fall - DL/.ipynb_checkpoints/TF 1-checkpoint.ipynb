{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_12:0\", shape=(), dtype=string)\n",
      "Tensor(\"Add_7:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우의 기본적인 구성을 익힙니다.\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.constant: 말 그대로 상수입니다.\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "print(hello)\n",
    "\n",
    "# Initialization\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "c = tf.add(a, b)  # a + b 로도 쓸 수 있음\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 변수와 수식들을 정의했지만, 실행이 정의한 시점에서 실행되는 것은 아닙니다.\n",
    "# 다음처럼 Session 객제와 run 메소드를 사용할 때 계산이 됩니다.\n",
    "# 따라서 모델을 구성하는 것과, 실행하는 것을 분리하여 프로그램을 깔끔하게 작성할 수 있습니다.\n",
    "# 그래프를 실행할 세션을 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n",
      "[10, 32, 42]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() \n",
    "print(sess.run(hello)) # sess.run: 설정한 텐서 그래프(변수나 수식 등등)를 실행합니다.\n",
    "print(sess.run([a, b, c]))\n",
    "sess.close() # 세션을 닫습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_3:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 플레이스홀더와 변수의 개념을 익혀봅니다\n",
    "\n",
    "# tf.placeholder: 계산을 실행할 때 입력값을 받는 변수로 사용합니다.\n",
    "# None 은 크기가 정해지지 않았음을 의미합니다.\n",
    "X = tf.placeholder(tf.float32, [None, 3])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X 플레이스홀더에 넣을 값 입니다.\n",
    "# 플레이스홀더에서 설정한 것 처럼, 두번째 차원의 요소의 갯수는 3개 입니다.\n",
    "x_data = [[1, 2, 3], [4, 5, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.Variable: 그래프를 계산하면서 최적화 할 변수들입니다. 이 값이 바로 신경망을 좌우하는 값들입니다.\n",
    "# tf.random_normal: 각 변수들의 초기값을 정규분포 랜덤 값으로 초기화합니다.\n",
    "W = tf.Variable(tf.random_normal([3, 2])) # 3*2 matrix\n",
    "b = tf.Variable(tf.random_normal([2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값과 변수들을 계산할 수식을 작성합니다.\n",
    "# tf.matmul 처럼 mat* 로 되어 있는 함수로 행렬 계산을 수행합니다.\n",
    "expr = tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== x_data ===\n",
      "[[1, 2, 3], [4, 5, 6]]\n",
      "=== W ===\n",
      "[[ 0.6674029  -0.8445294 ]\n",
      " [ 0.8015822  -0.16383329]\n",
      " [-0.8492099   0.07849837]]\n",
      "=== b ===\n",
      "[[ 0.17375691]\n",
      " [-0.08008603]]\n",
      "=== expr ===\n",
      "[[-0.1033055 -0.7629439]\n",
      " [ 1.502177  -3.8063796]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "# 위에서 설정한 Variable 들의 값들을 초기화 하기 위해\n",
    "# 처음에 tf.global_variables_initializer를 한 번 실행해야 합니다.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"=== x_data ===\")\n",
    "print(x_data)\n",
    "print(\"=== W ===\")\n",
    "print(sess.run(W))\n",
    "print(\"=== b ===\")\n",
    "print(sess.run(b))\n",
    "print(\"=== expr ===\")\n",
    "# expr 수식에는 X 라는 입력값이 필요합니다.\n",
    "# 따라서 expr 실행시에는 이 변수에 대한 실제 입력값을 다음처럼 넣어줘야합니다.\n",
    "print(sess.run(expr, feed_dict={X: x_data}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X_1:0\", dtype=float32)\n",
      "Tensor(\"Y_1:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# X 와 Y 의 상관관계를 분석하는 기초적인 선형 회귀 모델을 만들고 실행해봅니다.\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "\n",
    "# name: 나중에 텐서보드등으로 값의 변화를 추적하거나 살펴보기 쉽게 하기 위해 이름을 붙여줍니다.\n",
    "X = tf.placeholder(tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X 와 Y 의 상관 관계를 분석하기 위한 가설 수식을 작성합니다.\n",
    "# y = W * x + b\n",
    "# W 와 X 가 행렬이 아니므로 tf.matmul 이 아니라 기본 곱셈 기호를 사용했습니다.\n",
    "hypothesis = W * X + b\n",
    "\n",
    "# 손실 함수를 작성합니다.\n",
    "# mean(h - Y)^2 : 예측값과 실제값의 거리를 비용(손실) 함수로 정합니다.\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# 텐서플로우에 기본적으로 포함되어 있는 함수를 이용해 경사 하강법 최적화를 수행합니다.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "# 비용을 최소화 하는 것이 최종 목표\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.989072 [1.1005448] [0.11697155]\n",
      "1 0.10790237 [0.9599144] [0.05335933]\n",
      "2 0.0017901198 [0.9759839] [0.05872171]\n",
      "3 0.00049877993 [0.9749102] [0.0565838]\n",
      "4 0.00046067918 [0.9756938] [0.05530296]\n",
      "5 0.00043862406 [0.9762584] [0.05396484]\n",
      "6 0.00041778618 [0.97683126] [0.0526685]\n",
      "7 0.00039794072 [0.977388] [0.0514023]\n",
      "8 0.0003790387 [0.97793156] [0.05016661]\n",
      "9 0.00036103593 [0.9784621] [0.04896065]\n",
      "\n",
      "=== Test ===\n",
      "X: 5, Y: [4.9412713]\n",
      "X: 2.5, Y: [2.495116]\n"
     ]
    }
   ],
   "source": [
    "# 세션을 생성하고 초기화합니다.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # 최적화를 100번 수행합니다.\n",
    "    for step in range(10):\n",
    "        # sess.run 을 통해 train_op 와 cost 그래프를 계산합니다.\n",
    "        # 이 때, 가설 수식에 넣어야 할 실제값을 feed_dict 을 통해 전달합니다.\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "        print(step, cost_val, sess.run(W), sess.run(b))\n",
    "\n",
    "    # 최적화가 완료된 모델에 테스트 값을 넣고 결과가 잘 나오는지 확인해봅니다.\n",
    "    print(\"\\n=== Test ===\")\n",
    "    print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X: 5}))\n",
    "    print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X: 2.5}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
