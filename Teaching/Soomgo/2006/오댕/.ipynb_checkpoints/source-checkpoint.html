<!doctype html>
<html lang="en">
    <head>
    <title>Formulas for Bayesian A/B Testing – Evan Miller</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="author" content="Evan Miller">
    <meta property="og:title" content="Formulas for Bayesian A/B Testing">
    <meta property="og:description" content="A collection of closed-form equations for A/B testing binary and count data">
    <meta property="og:image" content="https://www.evanmiller.org/images/previews/bayesian-ab-testing.png">
    <meta property="og:url" content="https://www.evanmiller.org/bayesian-ab-testing.html">
    <meta name="twitter:card" content="summary_large_image">
    <link rel="alternate" type="application/rss+xml" href="news.xml">
    <link rel="stylesheet" type="text/css" href="./emiller.css">
    <link rel="stylesheet" type="text/css" href="./article.css">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: { equationNumbers: { autoNumber: "AMS" } },
      CommonHTML: { linebreaks: { automatic: true } },
      "HTML-CSS": { linebreaks: { automatic: true } },
             SVG: { linebreaks: { automatic: true } }
    });
    </script>
</head>
<body>
    <div id="content">
        <div class="header">
            <a href="index.html"><picture>
                <source
                    srcset="./header-dark.png 1x, ./header-dark@2x.png 2x"
                    media="(prefers-color-scheme: dark)">
                <img src="./header.png" srcset="./header.png 1x, ./header@2x.png 2x" />
                </picture></a>
        </div>
        <div class="article">
<h1>Formulas for Bayesian A/B Testing</h1>
<p>By <a href="/">Evan Miller</a></p>

<p><em>October 1, 2015</em> (<a href="#changes">Changes</a>)</p>





<p>This page collects a few formulas I’ve derived for evaluating A/B tests in a Bayesian context. The formulas on this page are closed-form, so you don’t need to do complicated integral evaluations; they can be computed with simple loops and a decent math library. The advantage of Bayesian formulas over the traditional frequentist formulas is that you don’t have to collect a pre-ordained sample size in order to get a valid result. (See <a href="how-not-to-run-an-ab-test.html">How Not To Run An A/B Test</a> for more context on the “peeking” problem, and <a href="sequential-ab-testing.html">Simple Sequential A/B Testing</a> for a frequentist solution to the problem.)</p> 

<h3>Table of Contents</h3>

<ol>
    <li><a href="#binary_ab">A/B testing: binary outcomes</a>
    <ol>
        <li><a href="#binary_ab_derivation">Derivation</a>
        <li><a href="#binary_ab_equivalent">Equivalent Formulas</a>
        <li><a href="#binary_ab_implementation">Implementation</a>
    </ol>
    <li><a href="#binary_abc">A/B/C testing: binary outcomes</a>
    <ol>
        <li><a href="#binary_abc_derivation">Derivation</a>
        <li><a href="#binary_abc_implementation">Implementation</a>
    </ol>
    <li><a href="#binary_abcd">A/B/C/D testing: binary outcomes</a>
    <ol>
        <li><a href="#binary_abcd_derivation">Derivation</a>
        <li><a href="#binary_abcd_implementation">Implementation</a>
    </ol>
    <li><a href="#count_ab">A/B testing: count data</a>
    <ol>
        <li><a href="#count_ab_derivation">Derivation</a>
        <li><a href="#count_ab_implementation">Implementation</a>
    </ol>
    <li><a href="#count_abc">A/B/C testing: count data</a>
    <ol>
        <li><a href="#count_abc_derivation">Derivation</a>
        <li><a href="#count_abc_implementation">Implementation</a>
    </ol>
</ol>

<hr>

<a name="binary_ab"></a>
<h2>A/B testing: binary outcomes</h2>

<p>For a binary-outcome test (e.g. a test of conversion rates), the probability that B will beat A in the long run is given by:</p>

\[
{\rm Pr}(p_B &gt; p_A) = \sum_{i=0}^{\alpha_B-1}{\frac{B(\alpha_A+i, \beta_B + \beta_A)}{(\beta_B+i)B(1+i,\beta_B)B(\alpha_A,\beta_A)}}
\]

<p>Where:<p>
<ul>
    <li>\(\alpha_A\) is one plus the number of successes for A</li>
    <li>\(\beta_A\) is one plus the number of failures for A</li>
    <li>\(\alpha_B\) is one plus the number of successes for B</li>
    <li>\(\beta_B\) is one plus the number of failures for B</li>
    <li>\(B\) is the <a href="https://en.wikipedia.org/wiki/Beta_function">beta function</a></li>
</ul>

<a name="binary_ab_derivation"></a>
<h3>Derivation</h3>

<p><em>Not for the timid! If calculus isn’t your cup of chamomile, skip right to the <a href="#implementation">implementation</a> section.</em></p>

<a name="cite1"></a>
<p>The <a href="https://en.wikipedia.org/wiki/Beta_distribution">beta distribution</a> is a convenient prior distribution for modeling a binomial parameter \(p\). Starting from a non-informative prior,<sup><a href="#notes">1</a></sup> the distribution of \(p\) after \(S\) successes and \(F\) failures is given by \({\rm Beta}(S+1, F+1)\). For the remainder of the discussion let \(\alpha=S+1\) and \(\beta=F+1\), which are just the two parameters of the beta distribution for the belief. </p>

<p>Now suppose we have two experimental branches (A and B) and have a Bayesian belief for each one:</p>

\[
\begin{array}{lr}
p_A \sim {\rm Beta}(\alpha_A, \beta_A) \\
p_B \sim {\rm Beta}(\alpha_B, \beta_B)
                        \end{array}
\]

<p>Using the pdf of the beta distribution, we can get the total probability that \(p_B\) is greater than \(p_A\) by integrating the joint distribution over all values for which \(p_B &gt; p_A\):</p>

\[
\begin{equation}
{\rm Pr}(p_B &gt; p_A) = \int_0^1 \int_{p_A}^1 \frac{p_A^{\alpha_A-1}(1-p_A)^{\beta_A-1}}{B(\alpha_A, \beta_A)} \frac{{p_B}^{\alpha_B-1}(1-p_B)^{\beta_B-1}}{B(\alpha_B, \beta_B)} dp_B dp_A
\end{equation}
\]

<p>Evaluating the inner integral, the equation becomes:</p>

\[
\begin{equation}
\label{binary_ab_pr_eval_inner}
{\rm Pr}(p_B &gt; p_A) = 1 - \int_0^1 \frac{p_A^{\alpha_A-1}(1-p_A)^{\beta_A-1}}{B(\alpha_A,\beta_A)}I_{p_A}(\alpha_B, \beta_B)dp_A
\end{equation}
\]

<p>Where \(I_x\) is the <a href="https://en.wikipedia.org/wiki/Beta_function#Incomplete_beta_function">regularized incomplete beta function</a>. Using the identity \(I_x(1,b) = 1 - (1 - x)^b\), the recursive relationship</p>

\[
\begin{equation}
I_x(a, b) = I_x(a-1, b) - \frac{x^{a-1}(1-x)^b}{(a-1)B(a-1,b)}
\end{equation}
\]

<p>and the fact that \(\alpha\) and \(\beta\) are integers, we can express \(I_x\) as:</p>

\[
\begin{equation}
I_x(a, b) = 1 - (1 - x)^b - \sum_{j=1}^{a-1}\frac{x^{a-j}(1-x)^b}{(a-j)B(a-j,b)}
\end{equation}
\]

<p>Or equivalently:</p>

\[
\begin{equation}
\label{ibeta_sum}
I_x(a, b) = 1 - \sum_{i=0}^{a-1} \frac{x^{i}(1 - x)^b}{(b+i)B(1+i,b)}
\end{equation}
\]

<p>The probability integral \(\eqref{binary_ab_pr_eval_inner}\) can therefore be written:</p>

\[
\begin{array}{ll}
{\rm Pr}(p_B &gt; p_A) &amp;=&amp; 1 - \int_0^1 \frac{p_A^{\alpha_A-1}(1-p_A)^{\beta_A-1}}{B(\alpha_A,\beta_A)} \left(1 - \sum_{i=0}^{\alpha_B-1}{\frac{p_A^i(1-p_A)^{\beta_B}}{(\beta_B+i)B(1+i, \beta_B)}}\right)dp_A \\
&amp;=&amp; 1 - 1 + \int_0^1 \frac{p_A^{\alpha_A-1}(1-p_A)^{\beta_A-1}}{B(\alpha_A,\beta_A)} \sum_{i=0}^{\alpha_B-1}{\frac{p_A^i(1-p_A)^{\beta_B}}{(\beta_B+i)B(1+i, \beta_B)}}dp_A \\
&amp;=&amp; \int_0^1 \sum_{i=0}^{\alpha_B-1}{\frac{p_A^{\alpha_A-1+i}(1-p_A)^{\beta_A+\beta_B-1}}{(\beta_B+i)B(\alpha_A, \beta_A)B(1+i, \beta_B)}}dp_A \\
&amp;=&amp; \sum_{i=0}^{\alpha_B-1}\int_0^1{\frac{p_A^{\alpha_A-1+i}(1-p_A)^{\beta_A+\beta_B-1}}{(\beta_B+i)B(\alpha_A, \beta_A)B(1+i, \beta_B)}}dp_A \\
&amp;=&amp; \sum_{i=0}^{\alpha_B-1}\frac{B(\alpha_A+i,\beta_A+\beta_B)}{(\beta_B+i)B(\alpha_A, \beta_A)B(1+i, \beta_B)} \int_0^1{\frac{p_A^{\alpha_A-1+i}(1-p_A)^{\beta_A+\beta_B-1}}{B(\alpha_A+i,\beta_A+\beta_B)}}dp_A 
                        \end{array}
\]

<p>Finally:</p>
\[
\begin{equation}
\label{binary_ab_pr_alpha_b}
{\rm Pr}(p_B &gt; p_A) = \sum_{i=0}^{\alpha_B-1}\frac{B(\alpha_A+i,\beta_A+\beta_B)}{(\beta_B+i) 
B(1+i, \beta_B)
B(\alpha_A, \beta_A)
}
\end{equation}
\]

<p><em><strong>Update, 6/8/2014:</strong> Chris Stucchio has derived a <a href="http://www.chrisstucchio.com/blog/2014/bayesian_ab_decision_rule.html">decision rule</a> and <a href="http://www.chrisstucchio.com/blog/2014/bayesian_asymptotics.html">asymptotic formula</a> using the above formula. Check them out!</em></p>

<a name="binary_ab_equivalent"></a>
<h3>Equivalent Formulas</h3>

<p>It’s possible to derive similar formulas that sum over the other three parameters:</p>

\[
\begin{align}
{\rm Pr}(p_B &gt; p_A) &amp;= 1 - \sum_{i=0}^{\alpha_A-1}{\frac{B(\alpha_B+i, \beta_B + \beta_A)}{(\beta_A+i)B(1+i,\beta_A)B(\alpha_B,\beta_B)}} \\
{\rm Pr}(p_B &gt; p_A) &amp;= \sum_{i=0}^{\beta_A-1}{\frac{B(\beta_B+i, \alpha_A + \alpha_B)}{(\alpha_A+i)B(1+i,\alpha_A)B(\alpha_B,\beta_B)}} \\
{\rm Pr}(p_B &gt; p_A) &amp;= 1 - \sum_{i=0}^{\beta_B-1}{\frac{B(\beta_A+i, \alpha_A + \alpha_B)}{(\alpha_B+i)B(1+i,\alpha_B)B(\alpha_A,\beta_A)}}
\end{align}
\]

<p>The above formulas can be found with symmetry arguments.</p>

<a name="binary_ab_implementation"></a>
<h3>Implementation</h3>

<p>Here’s a quick implementation of \(\eqref{binary_ab_pr_alpha_b}\) in Julia:</p>

<pre><code>using SpecialFunctions # for logbeta

function probability_B_beats_A(&alpha;_A, &beta;_A, &alpha;_B, &beta;_B)
    total = 0.0
    for i = 0:(&alpha;_B-1)
        total += exp(logbeta(&alpha;_A+i, &beta;_B+&beta;_A)
            - log(&beta;_B+i) - logbeta(1+i, &beta;_B) - logbeta(&alpha;_A, &beta;_A))
    end
    return total
end
</code></pre>

<p>The beta function produces very large numbers, so if you&#8217;re getting infinite values in your program, be sure to work with logarithms, as in the code above. Your standard library&#8217;s log-beta function will come in handy here.</p>

<p>If you don&#8217;t have log-beta available, it’s easy enough to define one with the log-gamma function and the identity:</p>

\[
\log(B(a, b)) = \log(\Gamma(a)) + \log(\Gamma(b)) - \log(\Gamma(a+b))
\]

<p>If you have neither log-beta nor log-gamma available, first rewrite the equation in terms of <a href="https://en.wikipedia.org/wiki/Gamma_function">gamma function</a>:</p>

\[
{\rm Pr}(p_B &gt; p_A) = \sum_{i=0}^{\alpha_B-1}\frac{\Gamma(\alpha_A+i)\Gamma(\beta_A+\beta_B)\Gamma(1+i+\beta_B)\Gamma(\alpha_A+\beta_A)}{(\beta_B+i) 
\Gamma(\alpha_A+i+\beta_A+\beta_B)
\Gamma(1+i)\Gamma(\beta_B)
\Gamma(\alpha_A)\Gamma(\beta_A)
}
\]

<p>Using the property that \(\Gamma(z)=(z-1)!\), notice that there are an equal number of multiplicative terms in the numerator and denominator. If you alternately multiply and divide one term at a time, you should be able to arrive at an answer without encountering numerical overflow.</p>

<p>As there are four equivalent formulas available, implementers concerned with computational efficiency may want to choose the formula that requires the smallest number of iterations for a particular set of \(\alpha\) and \(\beta\) values.</p>

<p>A final word of caution to implementers: when calling these functions, don&#8217;t forget to add 1 to the success and failure counts! Otherwise your results will be slightly off.</p>

<hr>
<a name="binary_abc"></a>
<h2>A/B/C testing: binary outcomes</h2>

<p>It is possible to extend the binary-outcome formula to three test groups, call them A, B, and C. The probability that C will beat both A and B in the long run is:</p>

\[
{\rm Pr}(p_C &gt; \max\{p_A, p_B\}) = \\ 1 - {\rm Pr}(p_A &gt; p_C) - {\rm Pr}(p_B &gt; p_C)
+ \sum_{i=0}^{\alpha_A-1} \sum_{j=0}^{\alpha_B-1}{\frac{B(i+j+\alpha_C, \beta_A + \beta_B + \beta_C)}{(\beta_A+i)B(1+i,\beta_A)(\beta_B+j)B(1+j,\beta_B)B(\alpha_C, \beta_C)}}
\]

<p>Where:<p>
<ul>
    <li>\(\alpha_X\) is one plus the number of successes for \(X \in \{A, B, C\}\)</li>
    <li>\(\beta_X\) is one plus the number of failures for \(X \in \{A, B, C\}\)</li>
    <li>\({\rm Pr}(p_X &gt; p_C)\) is the formula for the two-group case, given by \(\eqref{binary_ab_pr_alpha_b}\)</li>
</ul>

<p>Note that this formula can be computed in \(O(\alpha_A \alpha_B)\) time (see the <a href="#binary_abc_implementation">implementation</a> section below).</p>

<a name="binary_abc_derivation"></a>
<h3>Derivation</h3>

<p>Start with a Bayesian belief for each of three experimental branches (A, B, and C):</p>

\[
\begin{array}{lr}
p_A \sim {\rm Beta}(\alpha_A, \beta_A) \\
p_B \sim {\rm Beta}(\alpha_B, \beta_B) \\
p_C \sim {\rm Beta}(\alpha_C, \beta_C) \\
                        \end{array}
\]

<p>Calling the pdf of the beta distribution \(f(p|\alpha, \beta) = f(p)\), we can get the total probability that \(p_C\) is greater than both \(p_A\) and \(p_B\) by integrating the joint distribution over all values for which \(p_C &gt; p_A\) and \(p_C &gt; p_B\):</p>

\[
{\rm Pr}(p_C &gt; \max{\{p_A, p_B\}}) = \int_0^1 \int_0^{p_C} \int_0^{p_C} f(p_A) f(p_B) f(p_C) dp_A dp_B dp_C
\]

<p>Evaluating the inner two integrals, the equation becomes:</p>

\[
\begin{equation}
\label{binary_abc_pr_eval_inner}
{\rm Pr}(p_C &gt; \max{\{p_A, p_B\}}) = \int_0^1 I_{p_C}(\alpha_A, \beta_A) I_{p_C}(\alpha_B, \beta_B) f(p_C) dp_C
\end{equation}
\]

<p>Using the identity for \(I_X\) \(\eqref{ibeta_sum}\), we have:</p>

\[
{\rm Pr} = \int_0^1 
\left(1-\sum_{i=0}^{\alpha_A-1}\frac{p_C^i (1-p_C)^{\beta_A}}{(\beta_A+i)B(1+i,\beta_A)}\right) 
\left(1-\sum_{i=0}^{\alpha_B-1}\frac{p_C^i (1-p_C)^{\beta_B}}{(\beta_B+i)B(1+i,\beta_B)}\right) 
f(p_C) dp_C \\
\]

<p>Multiplying out the parenthetical terms and integrating them separately:</p>

\[
{\rm Pr} = 1 
- \int_0^1 \sum_{i=0}^{\alpha_A-1}\frac{p_C^i (1-p_C)^{\beta_A}}{(\beta_A+i)B(1+i,\beta_A)} f(p_C) dp_C 
- \int_0^1 \sum_{i=0}^{\alpha_B-1}\frac{p_C^i (1-p_C)^{\beta_B}}{(\beta_B+i)B(1+i,\beta_B)} f(p_C) dp_C
+ \int_0^1 \sum_{i=0}^{\alpha_A-1}\frac{p_C^i (1-p_C)^{\beta_A}}{(\beta_A+i)B(1+i,\beta_A)} 
\sum_{i=0}^{\alpha_B-1}\frac{p_C^i (1-p_C)^{\beta_B}}{(\beta_B+i)B(1+i,\beta_B)} f(p_C) dp_C
\]

<p>From the previous derivation, we can rewrite the first two integrals as \({\rm Pr}(p_A &gt; p_C)\) and \({\rm Pr}(p_B &gt; p_C)\), and consolidate the terms inside the third integral:</p>

\[
\begin{array}{ll}
{\rm Pr} &=& 1 - {\rm Pr}(p_A &gt; p_C) - {\rm Pr}(p_B &gt; p_C) \\
&& + \int_0^1 \sum_{i=0}^{\alpha_A-1} \sum_{j=0}^{\alpha_B-1} \frac{p_C^{i+j}(1-p_C)^{\beta_A+\beta_B}}{(\beta_A+i)(\beta_B+j)B(1+i,\beta_A)B(1+j,\beta_B)} \frac{p_C^{\alpha_C-1}(1-p_C)^{\beta_C-1}}{B(\alpha_C, \beta_C)} dp_C \\ \\
&=& 1 - {\rm Pr}(p_A &gt; p_C) - {\rm Pr}(p_B &gt; p_C) \\
&& + \int_0^1 \sum_{i=0}^{\alpha_A-1} \sum_{j=0}^{\alpha_B-1} \frac{p_C^{i+j+\alpha_C-1}(1-p_C)^{\beta_A+\beta_B+\beta_C-1}}{(\beta_A+i)(\beta_B+j)B(1+i,\beta_A)B(1+j,\beta_B)B(\alpha_C, \beta_C)} dp_C
\end{array}
\]

<p>Finally, evaluating the integral we have:</p>
\[
\begin{array}{ll}
{\rm Pr}(p_C &gt; \max\{p_A, p_B\}) &=& 1 - {\rm Pr}(p_A &gt; p_C) - {\rm Pr}(p_B &gt; p_C) \\
&& + \sum_{i=0}^{\alpha_A-1} \sum_{j=0}^{\alpha_B-1} \frac{B(i+j+\alpha_C, \beta_A+\beta_B+\beta_C)}{(\beta_A+i)(\beta_B+j)B(1+i,\beta_A)B(1+j,\beta_B)B(\alpha_C, \beta_C)}
\end{array}
\]

<a name="binary_abc_implementation"></a>
<h3>Implementation</h3>

<p>In Julia (taking advantage of <code><a href="#binary_ab_implementation">probability_B_beats_A</a></code> defined above):<p>

<pre><code>using SpecialFunctions # for logbeta

function probability_C_beats_A_and_B(&alpha;_A, &beta;_A, &alpha;_B, &beta;_B, &alpha;_C, &beta;_C)
    total = 0.0
    for i = 0:(&alpha;_A-1)
        for j = 0:(&alpha;_B-1)
          total += exp(logbeta(&alpha;_C+i+j, &beta;_A+&beta;_B+&beta;_C) - log(&beta;_A+i) - log(&beta;_B+j)
              - logbeta(1+i, &beta;_A) - logbeta(1+j, &beta;_B) - logbeta(&alpha;_C, &beta;_C))
        end
    end
    return (1 - probability_B_beats_A(&alpha;_C, &beta;_C, &alpha;_A, &beta;_A)
              - probability_B_beats_A(&alpha;_C, &beta;_C, &alpha;_B, &beta;_B) + total)
end
</code></pre>

<p>See the hints <a href="#binary_ab_implementation">above</a> if you don’t have a log-beta function in your language.</p>

<hr>
<a name="binary_abcd"></a>
<h2>A/B/C/D testing: binary outcomes</h2>

<p>The framework may be extended indefinitely to more variants, at increasing computational expense (and algebraic complexity). A derivation of a four-variant case (computable in \(O(\alpha_A \alpha_B \alpha_C)\) time) follows.</p>

<a name="binary_abcd_derivation"></a>
<h3>Derivation</h3>

<p>Beginning with</p>

\[
{\rm Pr}(p_D &gt; \max\{p_A, p_B, p_C\}) = \int_0^1 \int_0^{p_D} \int_0^{p_D} \int_0^{p_D} f(p_A) f(p_B) f(p_C) f(p_D) dp_A dp_B dp_C dp_D
\]

<p>The three inner integrals evaluate to </p>

\[
{\rm Pr}(p_D &gt; \max\{p_A, p_B, p_C\}) = \int_0^1 I_{p_D}(\alpha_A, \beta_A) I_{p_D}(\alpha_B, \beta_B) I_{p_D}(\alpha_C, \beta_C) f(p_D) dp_D
\]

<p>Using the identity</p>

\[
\begin{equation}
\label{beta_inverse_identity}
I_x(a, b) = 1 - I_{1-x}(b, a)
\end{equation}
\]

<p>We can write for the moment</p>

\[
\begin{array}{ll}
{\rm Pr}(p_D &gt; \max\{p_A, p_B, p_C\}) &=& 
\int_0^1 
I_{p_D}(\alpha_A, \beta_A) I_{p_D}(\alpha_B, \beta_B)
(1-I_{1-p_D}(\beta_C, \alpha_C))
f(p_D) dp_D \\
&=&
\int_0^1 
I_{p_D}(\alpha_A, \beta_A) I_{p_D}(\alpha_B, \beta_B)
f(p_D) dp_D \\
&& -\int_0^1 
I_{p_D}(\alpha_A, \beta_A) I_{p_D}(\alpha_B, \beta_B)
I_{1-p_D}(\beta_C, \alpha_C)
f(p_D) dp_D \\
\end{array}
\]
<p>Rewriting the first term</p>
\[
{\rm Pr}(p_D &gt; \max\{p_A, p_B, p_C\}) =
{\rm Pr}(p_D &gt; \max\{p_A, p_B\})
-\int_0^1 
I_{p_D}(\alpha_A, \beta_A) I_{p_D}(\alpha_B, \beta_B)
I_{1-p_D}(\beta_C, \alpha_C)
f(p_D) dp_D \\
\]

<p>And then rewriting the second term</p>
\[
{\rm Pr} =
{\rm Pr}(p_D &gt; \max\{p_A, p_B\})
-\int_0^1 
(1-I_{1-p_D}(\beta_A, \alpha_A))
(1-I_{1-p_D}(\beta_B, \alpha_B))
I_{1-p_D}(\beta_C, \alpha_C)
f(p_D) dp_D \\
\]

<p>Multiplying terms and separating the integrals</p>
\[
\begin{array}{ll}
{\rm Pr} &=&
{\rm Pr}(p_D &gt; \max\{p_A, p_B\})
-\int_0^1 
I_{1-p_D}(\beta_C, \alpha_C)
f(p_D) dp_D \\
&& +\int_0^1 
I_{1-p_D}(\beta_A, \alpha_A)
I_{1-p_D}(\beta_C, \alpha_C)
f(p_D) dp_D \\
&& +\int_0^1 
I_{1-p_D}(\beta_B, \alpha_B)
I_{1-p_D}(\beta_C, \alpha_C)
f(p_D) dp_D \\
&& -\int_0^1 
I_{1-p_D}(\beta_A, \alpha_A)
I_{1-p_D}(\beta_B, \alpha_B)
I_{1-p_D}(\beta_C, \alpha_C)
f(p_D) dp_D \\
\end{array}
\]

<p>Equations \(\eqref{ibeta_sum}\) and \(\eqref{beta_inverse_identity}\) imply</p>

\[
\begin{equation}
\label{beta_inverse_sum}
I_{1-p_D}(\beta, \alpha) = \sum_{i=0}^{\alpha-1} \frac{p_D^{i}(1 - p_D)^\beta}{(\beta+i)B(1+i,\beta)}
\end{equation}
\]

<p>Rewriting the first integral using the two-variant formula, and the next two integrals using the three-variant formula,</p>

\[
\begin{array}{ll}
{\rm Pr} &=&
{\rm Pr}(p_D &gt; \max\{p_A, p_B\}) -{\rm Pr}(p_C &gt; p_D) \\
&& -\left(1-{\rm Pr}(p_A &gt; p_D) - {\rm Pr}(p_C &gt; p_D) - {\rm Pr}(p_D &gt; \max\{p_A, p_C\})\right) \\
&& -\left(1-{\rm Pr}(p_B &gt; p_D) - {\rm Pr}(p_C &gt; p_D) - {\rm Pr}(p_D &gt; \max\{p_B, p_C\})\right) \\
&& -\int_0^1 
I_{1-p_D}(\beta_A, \alpha_A)
I_{1-p_D}(\beta_B, \alpha_B)
I_{1-p_D}(\beta_C, \alpha_C)
f(p_D) dp_D \\
\end{array}
\]

<p>Combining</p>

\[
\begin{array}{ll}
{\rm Pr} &=&
-2 + {\rm Pr}(p_A &gt; p_D) + {\rm Pr}(p_B &gt; p_D) + {\rm Pr}(p_C &gt; p_D) \\
&& + {\rm Pr}(p_D &gt; \max\{p_A, p_B\}) \\
&& + {\rm Pr}(p_D &gt; \max\{p_A, p_C\}) \\
&& + {\rm Pr}(p_D &gt; \max\{p_B, p_C\}) \\
&& -\int_0^1 
I_{1-p_D}(\beta_A, \alpha_A)
I_{1-p_D}(\beta_B, \alpha_B)
I_{1-p_D}(\beta_C, \alpha_C)
f(p_D) dp_D \\
\end{array}
\]

<p>Or</p>

\[
\begin{array}{ll}
{\rm Pr} &=&
1 - {\rm Pr}(p_D &gt; p_A) - {\rm Pr}(p_D &gt; p_B) - {\rm Pr}(p_D &gt; p_C) \\
&& + {\rm Pr}(p_D &gt; \max\{p_A, p_B\}) \\
&& + {\rm Pr}(p_D &gt; \max\{p_A, p_C\}) \\
&& + {\rm Pr}(p_D &gt; \max\{p_B, p_C\}) \\
&& -\int_0^1 
I_{1-p_D}(\beta_A, \alpha_A)
I_{1-p_D}(\beta_B, \alpha_B)
I_{1-p_D}(\beta_C, \alpha_C)
f(p_D) dp_D \\
\end{array}
\]

<p>Using \(\eqref{beta_inverse_sum}\) the final integral evaluates to</p>

\[
 \sum_{i=0}^{\alpha_A-1}\sum_{j=0}^{\alpha_B-1}\sum_{k=0}^{\alpha_C-1} \frac{B(i+j+k+\alpha_D, \beta_A + \beta_B + \beta_C + \beta_D)}{(\beta_A+1)(\beta_B+1)(\beta_C+1)B(1+i,\beta_A)B(1+j,\beta_B)B(1+k,\beta_C)B(\alpha_D,\beta_D)}
\]

<p>Yielding at last</p>

\[
\begin{array}{ll}
{\rm Pr}(p_D &gt; \max\{p_A, p_B, p_C\}) &=&
1
- {\rm Pr}(p_D &gt; p_A)
- {\rm Pr}(p_D &gt; p_B)
- {\rm Pr}(p_D &gt; p_C) \\
&& + {\rm Pr}(p_D &gt; \max\{p_A, p_B\}) \\
&& + {\rm Pr}(p_D &gt; \max\{p_A, p_C\}) \\
&& + {\rm Pr}(p_D &gt; \max\{p_B, p_C\}) \\
&& - \sum_{i=0}^{\alpha_A-1}\sum_{j=0}^{\alpha_B-1}\sum_{k=0}^{\alpha_C-1} \frac{B(i+j+k+\alpha_D, \beta_A + \beta_B + \beta_C + \beta_D)}{(\beta_A+i)(\beta_B+j)(\beta_C+k)B(1+i,\beta_A)B(1+j,\beta_B)B(1+k,\beta_C)B(\alpha_D,\beta_D)}
\end{array}
\]

<a name="binary_abcd_implementation"></a>
<h3>Implementation</h3>

<p>In Julia (taking advantage of <code><a href="#binary_abc_implementation">probability_C_beats_A_and_B</a></code> and <code><a href="#binary_ab_implementation">probability_B_beats_A</a></code>):</p>
<pre><code>using SpecialFunctions # for logbeta

function probability_D_beats_ABC(&alpha;_A, &beta;_A, &alpha;_B, &beta;_B, &alpha;_C, &beta;_C, &alpha;_D, &beta;_D)
    total = 0.0
    for i = 0:(&alpha;_A-1)
        for j = 0:(&alpha;_B-1)
            for k = 0:(&alpha;_C-1)
              total += exp(logbeta(&alpha;_D+i+j+k, &beta;_A+&beta;_B+&beta;_C+&beta;_D) 
                           - log(&beta;_A+i) - log(&beta;_B+j) - log(&beta;_C+k)
                           - logbeta(1+i, &beta;_A) - logbeta(1+j, &beta;_B) - logbeta(1+k, &beta;_C) 
                           - logbeta(&alpha;_D, &beta;_D))
            end
        end
    end
    return (1 - probability_B_beats_A(&alpha;_A, &beta;_A, &alpha;_D, &beta;_D)
              - probability_B_beats_A(&alpha;_B, &beta;_B, &alpha;_D, &beta;_D)
              - probability_B_beats_A(&alpha;_C, &beta;_C, &alpha;_D, &beta;_D)
              + probability_C_beats_A_and_B(&alpha;_A, &beta;_A, &alpha;_B, &beta;_B, &alpha;_D, &beta;_D)
              + probability_C_beats_A_and_B(&alpha;_A, &beta;_A, &alpha;_C, &beta;_C, &alpha;_D, &beta;_D)
              + probability_C_beats_A_and_B(&alpha;_B, &beta;_B, &alpha;_C, &beta;_C, &alpha;_D, &beta;_D)
              - total)
end
</code></pre>

<p>If the above code is too slow for you, try building lookup tables to cache the results of <code>log</code> and <code>logbeta</code>.</p>

<hr>
<a name="count_ab"></a>
<h2>A/B testing: count data</h2>

<p>Analyzing count data (for example, if you’re comparing the number of sales per salesman, or number of sales week over week) requires a different formula. The probability that group 1 has a higher arrival rate than group 2 is given by:</p>

\[
{\rm Pr}(\lambda_1 &gt; \lambda_2) = \sum_{k=0}^{\alpha_1-1} \frac{
(\beta_1 + \beta_2)^{-(k+\alpha_2)}
\beta_1^k \beta_2^{\alpha_2}
}{(k+\alpha_2)B(k+1,\alpha_2)}
\]

<p>Here the \(\alpha\) values represent the total event counts in each group, and the \(\beta\) values represent the <a href="https://en.wikipedia.org/wiki/Poisson_regression#.22Exposure.22_and_offset">exposure</a>, that is, the relative opportunity for events to occur. For example, if the first group was “exposed” to events for twice as long as the second group, you would set \(\beta_1 = 2\) and \(\beta_2 = 1\). (Alternatively, you could set \(\beta_1 = 20\) and \(\beta_2 = 10\); the math works out the same.) In the above equation, \(B\) is the <a href="https://en.wikipedia.org/wiki/Beta_function">beta function</a>.</p>

<p>A derivation and implementation follow; they both closely mirror the binary-outcome case.</p>

<a name="count_ab_derivation"></a>
<h3>Derivation</h3>

<p><em>Not for the timid! You may want to skip right to the <a href="#count_ab_implementation">implementation</a> section.</em></p>

<p>Let \(\lambda_1\) and \(\lambda_2\) be the Poisson parameter for each group. With a gamma-distributed prior belief, the posterior beliefs are given by:</p>

\[
\begin{array}{lr}
\lambda_1 \sim {\rm Gamma}(\alpha_1, \beta_1) \\
\lambda_2 \sim {\rm Gamma}(\alpha_2, \beta_2)
                        \end{array}
\]

<p>Using the pdf of the gamma distribution, we can get the total probability that \(\lambda_1\) is greater than \(\lambda_2\) by integrating the joint distribution over all values for which \(\lambda_1 &gt; \lambda_2\):</p>

\[
\begin{equation}
{\rm Pr}(\lambda_1 &gt; \lambda_2) = \int_0^\infty \int_{\lambda_2}^\infty 
\frac{\beta_1^{\alpha_1} \lambda_1^{\alpha_1 - 1} e^{-\beta_1 \lambda_1}}{\Gamma(\alpha_1)}
\frac{\beta_2^{\alpha_2} \lambda_2^{\alpha_2 - 1} e^{-\beta_2 \lambda_2}}{\Gamma(\alpha_2)}
d\lambda_1 d\lambda_2
\end{equation}
\]

<p>Evaluating the inner integral, the equation becomes:</p>

\[
\begin{equation}
\label{count_ab_pr_eval_inner}
\int_0^\infty 
Q(\alpha_1, \beta_1 \lambda_2) 
\frac{\beta_2^{\alpha_2} \lambda_2^{\alpha_2-1} e^{-\beta_2 \lambda_2}}{\Gamma(\alpha_2)}
d\lambda_2
\end{equation}
\]

<p>Where \(Q\) is the <a href="https://en.wikipedia.org/wiki/Incomplete_Gamma_function#Regularized_Gamma_functions_and_Poisson_random_variables">upper incomplete regularized gamma function</a>. Using the identity \(Q(1,z) = e^{-z}\) and the recursive relationship</p>

\[
\begin{equation}
Q(a + n, z) = Q(a, z) + z^a e^{-z} \sum_{k=0}^{n-1} \frac{z^k}{\Gamma(a+k+1)}
\end{equation}
\]

<p>we can express \(Q\) as:</p>

\[
\begin{equation}
\label{igamma_sum}
Q(n, z) = e^{-z}\sum_{k=0}^{n-1}\frac{z^k}{\Gamma(k+1)}
\end{equation}
\]

<p>The probability integral \(\eqref{count_ab_pr_eval_inner}\) can therefore be written:</p>

\[
\begin{array}{ll}
{\rm Pr}(\lambda_1 &gt; \lambda_2) &amp;=&amp; \int_0^\infty e^{-\beta_1 \lambda_2} \left( \sum_{k=0}^{\alpha_1-1} \frac{(\beta_1 \lambda_2)^k}{\Gamma(k+1)}\right) \frac{\beta_2^{\alpha_2} \lambda_2^{\alpha_2-1} e^{-\beta_2 \lambda_2}}{\Gamma(\alpha_2)} d\lambda_2 \\
&amp;=&amp; \sum_{k=0}^{\alpha_1-1} \int_0^\infty \frac{e^{-\beta_1 \lambda_2} (\beta_1 \lambda_2)^k}{\Gamma(k+1)} \frac{\beta_2^{\alpha_2} \lambda_2^{\alpha_2-1} e^{-\beta_2 \lambda_2}}{\Gamma(\alpha_2)} d\lambda_2 \\
&amp;=&amp; \sum_{k=0}^{\alpha_1-1} \frac{\beta_1^k \beta_2^{\alpha_2}}{\Gamma(k+1) \Gamma(\alpha_2)} \int_0^\infty e^{-(\beta_1+\beta_2) \lambda_2} \lambda_2^{k+\alpha_2-1} d\lambda_2 \\
&amp;=&amp; \sum_{k=0}^{\alpha_1-1} \frac{\beta_1^k \beta_2^{\alpha_2}}{\Gamma(k+1) \Gamma(\alpha_2)} (\beta_1 + \beta_2)^{-(k+\alpha_2)} \Gamma(k+\alpha_2) \\
&amp;=&amp; \sum_{k=0}^{\alpha_1-1} \beta_1^k \beta_2^{\alpha_2} (\beta_1 + \beta_2)^{-(k+\alpha_2)} \frac{\Gamma(k+\alpha_2)}{\Gamma(k+1) \Gamma(\alpha_2)} \frac{k+\alpha_2}{k+\alpha_2}
\end{array}
\]

<p>Using \(\Gamma(z+1) = z\Gamma(z)\), we have:</p>

\[
\begin{equation}
\label{gamma_version}
{\rm Pr}(\lambda_1 &gt; \lambda_2) = \sum_{k=0}^{\alpha_1-1} \beta_1^k \beta_2^{\alpha_2} (\beta_1 + \beta_2)^{-(k+\alpha_2)} \frac{\Gamma(k+\alpha_2+1)}{\Gamma(k+1) \Gamma(\alpha_2)} \frac{1}{k+\alpha_2}
\end{equation}
\]

<p>Replacing the gamma functions with a beta function, we have:</p>
\[
\begin{equation}
\label{count_ab_pr_alpha_b}
{\rm Pr}(\lambda_1 &gt; \lambda_2) = \sum_{k=0}^{\alpha_1-1} \frac{
(\beta_1 + \beta_2)^{-(k+\alpha_2)}
\beta_1^k \beta_2^{\alpha_2}
}{(k+\alpha_2)B(k+1,\alpha_2)}
\end{equation}
\]

<a name="count_ab_implementation"></a>
<h3>Implementation</h3>

<p>Here’s a quick implementation of \(\eqref{count_ab_pr_alpha_b}\) in Julia:</p>

<pre><code>using SpecialFunctions # for logbeta

function probability_1_beats_2(&alpha;_1, &beta;_1, &alpha;_2, &beta;_2)
    total = 0.0
    for k = 0:(&alpha;_1-1)
        total += exp(k * log(&beta;_1) + &alpha;_2 * log(&beta;_2) - (k+&alpha;_2) * log(&beta;_1 + &beta;_2)
            - log(k + &alpha;_2) - logbeta(k + 1, &alpha;_2))
    end
    return total
end
</code></pre>

<p>The beta function produces very large numbers, so if you&#8217;re getting infinite values in your program, be sure to work with logarithms, as in the code above. Your standard library&#8217;s log-beta function will come in handy here.</p>

<p>If you don&#8217;t have log-beta available, it’s easy enough to define one with the log-gamma function and the identity:</p>

\[
\log(B(a, b)) = \log(\Gamma(a)) + \log(\Gamma(b)) - \log(\Gamma(a+b))
\]

<p>For more life-changing tips see the <a href="#binary_ab_implementation">implementation</a> section for the binary-outcome case.</p>

<hr>

<a name="count_abc"></a>
<h2>A/B/C testing: count data</h2>

<p>The count data formula above can be extended to three groups:</p>

\[
{\rm Pr}(\lambda_1 &gt; \max\{\lambda_2, \lambda_3\}) = 1 - {\rm Pr}(\lambda_2 &gt; \lambda_1) - {\rm Pr}(\lambda_3 &gt; \lambda_1) \\
+ \sum_{k=0}^{\alpha_2-1} \sum_{l=0}^{\alpha_3-1} \frac{\beta_1^{\alpha_1} \beta_2^k \beta_3^l}{(\beta_1 + \beta_2 + \beta_3)^{(k+l+\alpha_1)}} \frac{\Gamma(k+l+\alpha_1)}{\Gamma(k+1) \Gamma(l+1) \Gamma(\alpha_1)}
\]

<p>Where:</p>

<ul>
    <li>\(\lambda_n\) is the arrival rate for group \(n \in \{1, 2, 3\}\)</li>
    <li>\(\beta_n\) is the exposure of group \(n \in \{1, 2, 3\}\)</li>
    <li>\({\rm Pr}(\lambda_n &gt; \lambda_1)\) is the formula for the two-group case, given by \(\eqref{count_ab_pr_alpha_b}\)</li>
</ul>

<a name="count_abc_derivation"></a>
<h3>Derivation</h3>

<p>Start with a Bayesian belief for each of three experimental branches (A, B, and C):</p>

\[
\begin{array}{lr}
\lambda_1 \sim {\rm Gamma}(\alpha_1, \beta_1) \\
\lambda_2 \sim {\rm Gamma}(\alpha_2, \beta_2) \\
\lambda_2 \sim {\rm Gamma}(\alpha_3, \beta_3)
\end{array}
\]

<p>Calling the pdf of the gamma distribution \(g(\lambda|\alpha, \beta) = g(\lambda)\), we can construct the total probability that \(\lambda_1\) is greater than \(\lambda_2\) and \(\lambda_3\) with a triple integral:</p>

\[
{\rm Pr}(\lambda_1 &gt; \max\{\lambda_2, \lambda_3\}) = \int_0^\infty \int_0^{\lambda_1} \int_0^{\lambda_1} g(\lambda_3) g(\lambda_2) g(\lambda_1) d\lambda_3 d\lambda_2 d\lambda_1
\]

<p>Evaluating the two inner integrals (using the <a href="https://en.wikipedia.org/wiki/Incomplete_Gamma_function#Regularized_Gamma_functions_and_Poisson_random_variables">upper incomplete regularized gamma function</a> as before), we can write:</p>

\[
{\rm Pr}(\lambda_1 &gt; \max\{\lambda_2, \lambda_3\}) = \int_0^\infty (1-Q(\alpha_2, \beta_2 \lambda_1))(1-Q(\alpha_3, \beta_3 \lambda_1)) g(\lambda_1) d\lambda_1
\]

<p>Multiplying out the parenthetical terms and distributing the integral across the four resulting terms:</p>

\[
{\rm Pr} = 1 - \int_0^\infty Q(\alpha_2, \beta_2 \lambda_1) g(\lambda_1) d\lambda_1 - \int_0^\infty Q(\alpha_3, \beta_3 \lambda_1) g(\lambda_1) d\lambda_1 \\
+ \int_0^\infty Q(\alpha_2, \beta_2 \lambda_1) Q(\alpha_3, \beta_3 \lambda_1) g(\lambda_1) d\lambda_1
\]

<p>Following the previous derivation, we can rewrite the first two integrals as \({\rm Pr}(\lambda_2 &gt; \lambda_1)\) and \({\rm Pr}(\lambda_3 &gt; \lambda_1)\), and then write the remaining \(Q\) terms as summations:</p>

\[
{\rm Pr} = 1 - {\rm Pr}(\lambda_2 &gt; \lambda_1) - {\rm Pr}(\lambda_3 &gt; \lambda_1) \\
+ \int_0^\infty 
   e^{-\beta_2\lambda_1} \left(\sum_{k=0}^{\alpha_2-1} \frac{(\beta_2 \lambda_1)^k}{\Gamma(k+1)} \right) 
   e^{-\beta_3\lambda_1} \left(\sum_{l=0}^{\alpha_3-1} \frac{(\beta_3 \lambda_1)^l}{\Gamma(l+1)} \right) 
   g(\lambda_1) d\lambda_1
\]

<p>Writing out \(g\) explicitly and consolidating terms:</p>

\[
{\rm Pr} = 1 - {\rm Pr}(\lambda_2 &gt; \lambda_1) - {\rm Pr}(\lambda_3 &gt; \lambda_1) \\
+ \int_0^\infty 
   e^{-\lambda_1(\beta_1+\beta_2+\beta_3)} 
   \sum_{k=0}^{\alpha_2-1} 
   \sum_{l=0}^{\alpha_3-1} 
   \frac{\beta_1^{\alpha_1} \beta_2^k \beta_3^l \lambda_1^{(k+l+\alpha_1-1)}}{\Gamma(k+1)\Gamma(l+1)\Gamma(\alpha_1)} 
   d\lambda_1
\]

<p>Bringing the integral inside the summations:</p>

\[
{\rm Pr} = 1 - {\rm Pr}(\lambda_2 &gt; \lambda_1) - {\rm Pr}(\lambda_3 &gt; \lambda_1) \\
+ 
   \sum_{k=0}^{\alpha_2-1} 
   \sum_{l=0}^{\alpha_3-1} 
   \frac{\beta_1^{\alpha_1} \beta_2^k \beta_3^l}{\Gamma(k+1)\Gamma(l+1)\Gamma(\alpha_1)} 
   \int_0^\infty 
   e^{-\lambda_1(\beta_1+\beta_2+\beta_3)} \lambda_1^{(k+l+\alpha_1-1)}
   d\lambda_1
\]

<p>And evaluating it:</p>

\[
{\rm Pr} = 1 - {\rm Pr}(\lambda_2 &gt; \lambda_1) - {\rm Pr}(\lambda_3 &gt; \lambda_1) \\
+ 
   \sum_{k=0}^{\alpha_2-1} 
   \sum_{l=0}^{\alpha_3-1} 
   \frac{\beta_1^{\alpha_1} \beta_2^k \beta_3^l}{\Gamma(k+1)\Gamma(l+1)\Gamma(\alpha_1)} 
   \frac{\Gamma(k+l+\alpha_1)}{(\beta_1+\beta_2+\beta_3)^{(k+l+\alpha_1)}}
\]

<p>Rearranging, we finally have:</p>

\[
\begin{equation}
\label{count_abc_pr_alpha_b}
{\rm Pr} = 1 - {\rm Pr}(\lambda_2 &gt; \lambda_1) - {\rm Pr}(\lambda_3 &gt; \lambda_1) \\
+ 
   \sum_{k=0}^{\alpha_2-1} 
   \sum_{l=0}^{\alpha_3-1} 
   \frac{\beta_1^{\alpha_1} \beta_2^k \beta_3^l}{(\beta_1+\beta_2+\beta_3)^{(k+l+\alpha_1)}}
   \frac{\Gamma(k+l+\alpha_1)}{\Gamma(k+1)\Gamma(l+1)\Gamma(\alpha_1)} 
\end{equation}
\]

<p>It also is possible to rewrite the gamma functions in terms of a single, multivariate beta function, but that doesn’t necessarily increase the equation’s clarity.</p>

<a name="count_abc_implementation"></a>
<h3>Implementation</h3>

<p>In Julia, leveraging the <code>probability_1_beats_2</code> function above, we can compute \(\eqref{count_abc_pr_alpha_b}\) with:</p>

<pre><code>using SpecialFunctions # for loggamma

function probability_1_beats_2_and_3(&alpha;_1, &beta;_1, &alpha;_2, &beta;_2, &alpha;_3, &beta;_3)
    total = 0.0
    for k = 0:(&alpha;_2-1)
        for l = 0:(&alpha;_3-1)
            total += exp(&alpha;_1 * log(&beta;_1) + k * log(&beta;_2) + l * log(&beta;_3) 
                - (k+l+&alpha;_1) * log(&beta;_1 + &beta;_2 + &beta;_3)
                + loggamma(k+l+&alpha;_1) - loggamma(k+1) - loggamma(l+1) - loggamma(&alpha;_1))
        end
    end
    return (1 - probability_1_beats_2(&alpha;_2, &beta;_2, &alpha;_1, &beta;_1)
              - probability_1_beats_2(&alpha;_3, &beta;_3, &alpha;_1, &beta;_1) + total)
end
</code></pre>

<p>And that’s a wrap!</p>

<hr>

<a name="notes"></a>
<h2>Notes</h2>

<ol class="footnotes">
<li><p>An informative prior can also be used here, with the restriction that \(\alpha\) and \(\beta\) remain integers. <a href="#cite1">⇧</a></p></li>
</ol>

<hr>

<a name="changes"></a>
<h2>Changes</h2>

<ul>
    <li>April 8, 2020 - Added a section for binary-outcome A/B/C/D tests.</li>
    <li>April 4, 2020 – Fixed a trivial typo in equation \(\eqref{binary_abc_pr_eval_inner}\).
        Fixed buggy return expressions in the Julia code for A/B/C functions.
        Updated Julia code to eschew deprecated functions (<code>logbeta</code> replaces <code>lbeta</code>, <code>loggamma</code> replaces <code>lgamma</code>).
    </li>
    <li>October 1, 2015 – Added formulas for A/B/C tests. Consolidated binary-outcome and count-data formulas into one article.</li>
    <li>June 8, 2014 – Link to Chris Stucchio’s work.</li>
    <li>June 6, 2014 – Initial version.</li>
</ul>


<hr>

<p><em>You’re reading <a href="/">evanmiller.org</a>, a random collection of math, tech, and musings. If you liked this you might also enjoy:
    <ul>
        <li><a href="bayesian-average-ratings.html">Bayesian Average Ratings</a>
        <li><a href="ranking-items-with-star-ratings.html">Ranking Items With Star Ratings: An Approximate Bayesian Approach</a>
        <li><a href="how-not-to-run-an-ab-test.html">How Not To Run an A/B Test</a>
        <li><a href="sequential-ab-testing.html">Simple Sequential A/B Testing</a>
    </ul>
</em>
</p>

<hr>
<p><em>Get new articles as they’re published, via <a href="https://twitter.com/EvMill">Twitter</a> or <a href="/news.xml">RSS</a>.</em></p>

<hr>

<p><em>Want to look for statistical patterns in your MySQL, PostgreSQL, or SQLite database? My desktop statistics software <strong><a href="https://www.wizardmac.com/">Wizard</a></strong> can help you analyze <strong>more data in less time</strong> and <strong>communicate discoveries visually</strong> without spending days struggling with pointless command syntax. Check it out!</em></p>
<div style="text-align: center">
<a href="https://www.wizardmac.com/"><img height="128" width="128" src="./images/index/wizard-nonpro.png"></a><br>
<strong><a href="https://www.wizardmac.com/">Wizard</a></strong><br><span style="color: #777; font-size: 14px">Statistics the Mac way</span>
</div>

<hr>

<p><a href="/">Back to Evan Miller’s home page</a> 
– <a href="/news.xml">Subscribe to RSS</a>
– <a href="https://twitter.com/EvMill">Twitter</a> 
– <a href="https://www.youtube.com/c/EvanMiller">YouTube</a> 
</p>

<hr>

</div>
</div>
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-5838049-1', 'auto');
  ga('send', 'pageview');
</script>
</body>
</html>
